# config/llm_council.yaml (actualizado)
llm_configs:
  # Modelos SOTA para el consejo
  claude-3-5-sonnet:
    provider: openrouter
    model: claude-3.5-sonnet
    max_tokens: 4000
    temperature: 0.1
    priority: 1
    
  gpt-4-turbo:
    provider: openrouter  
    model: gpt-4-turbo
    max_tokens: 4000
    temperature: 0.1
    priority: 2
    
  deepseek-coder:
    provider: openrouter
    model: deepseek-coder
    max_tokens: 4000
    temperature: 0.1
    priority: 3
    
  gemini-pro:
    provider: openrouter
    model: gemini-pro
    max_tokens: 4000
    temperature: 0.1
    priority: 4
    
  llama-3-1-70b:
    provider: openrouter
    model: llama-3.1-70b
    max_tokens: 4000
    temperature: 0.1
    priority: 5
    
  codellama-70b:
    provider: openrouter
    model: codellama-70b
    max_tokens: 4000
    temperature: 0.1
    priority: 6

# Configuración del consejo
council_settings:
  min_llms: 3
  max_llms: 5
  preferred_count: 3  # Impar para votación
  timeout_seconds: 300
  enable_discussion: true
  
# Configuración de máquinas de estados
state_machine_settings:
  max_analysis_time: 60
  max_test_design_time: 45
  max_fix_design_time: 90
  max_documentation_time: 30
  enable_state_persistence: true
  state_checkpoint_dir: "./tdh_states"
  
# Prompts personalizados por estado
state_prompts:
  analyzing:
    system: "Eres un experto en seguridad de código. Analiza esta vulnerabilidad detalladamente."
    temperature: 0.1
    
  test_designing:
    system: "Eres un ingeniero de pruebas de seguridad. Diseña tests que demuestren vulnerabilidades."
    temperature: 0.2
    
  fix_designing:
    system: "Eres un ingeniero de seguridad que escribe código seguro y mantiene funcionalidad."
    temperature: 0.1
    
  documenting:
    system: "Eres un documentador técnico especializado en seguridad de código."
    temperature: 0.1